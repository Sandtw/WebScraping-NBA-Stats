{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Descargar votos de MVP con requests**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se extrae el contenedor que contiene los mejores jugadores por temporada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MVP1](images/mvp_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1991, 2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_start = \"https://www.basketball-reference.com/awards/awards_{}.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "for year in years:\n",
    "    url = url_start.format(year)\n",
    "    data = requests.get(url)\n",
    "\n",
    "    # w+ : Un archivo para escritura y lectura\n",
    "    with open(\"mvp/{}.html\".format(year), \"w+\", encoding= \"utf-8\") as f:\n",
    "        f.write(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Analizando la tabla de votos con beautifulsoup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mvp/1991.html\", encoding='UTF-8') as f:\n",
    "    page = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera práctica, eliminaremos el 1er encabezado, para poder solo incluir las filas que nos importa y convertirlo aun DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MVP2](images/mvp_02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "soup.find('tr', class_ = 'over_header').decompose() #* Elimina el 1er encabezado \n",
    "mvp_table = soup.find(id=\"mvp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_1991 = pd.read_html(str(mvp_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Nos devuelve una lista de DataFrames \n",
    "mvp_1991 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_1991 = pd.read_html(str(mvp_table))[0]\n",
    "mvp_1991"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacando todos los DataFrames de todas las temporadas en una sola lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in years:\n",
    "    with open('mvp/{}.html'.format(year), encoding='utf-8') as f:\n",
    "        page = f.read()\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        soup.find('tr', class_ = 'over_header').decompose()\n",
    "        mvp_table = soup.find(id='mvp')\n",
    "        mvp = pd.read_html(str(mvp_table))[0]\n",
    "        mvp[\"year\"] = year\n",
    "\n",
    "        dfs.append(mvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Combinando votos MVP con pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps = pd.concat(dfs)\n",
    "mvps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps.to_csv('mvps.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1. Descarga de estadísticas de jugadores**\n",
    "\n",
    "Ya que conocemos los MVP de las temporadas 1991-2021, se procederá a captar todos los jugadores de las temporadas, de tal manera poder entrenar un algoritmo de ML que pueda predecir que jugador de la siguietne temporada será el MVP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PLAYER1](images/player_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Al tener el enlace de las estadísticas por jugador/juego, solo me mostrará las primeras 17 filas, y luego mostrará las siguientes 17 filas conforme se vaya haciendo scroll mediante código javascript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Usando Selenium para screappear una página de Javascript**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es un problema muy común en el webscrapping, muchos sitios web tendrán javascript u otros componenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = player_stats_url.format(1991)\n",
    "data = requests.get(url)\n",
    "with open(\"player/1991.html\", \"w+\", encoding='utf-8') as f:\n",
    "    f.write(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PLAYER2](images/player_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previamente instalamos [ChromeDriver](https://chromedriver.chromium.org/) según tu SO, es un servidor independiente que implementa el protocolo de cable de WebDriver para Chromium. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp\\ipykernel_28208\\4140206510.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path = \"C:\\ChromeDriver\\chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "# Crea una ventana que está siendo controlada por Selenium\n",
    "# Usaremos ese navegador para mostrar la pagina con todas las filas que necesitamos\n",
    "driver = webdriver.Chrome(executable_path = \"C:\\ChromeDriver\\chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "year = 1991\n",
    "url = player_stats_url.format(year)\n",
    "\n",
    "#Renderice la URL en el navegador\n",
    "driver.get(url) \n",
    "\n",
    "#Ejecutamos un poco de javascript en el navegador\n",
    " #? Comando de JS que solo dice al navegador para desplazarse hacia abajo\n",
    "driver.execute_script(\"window.scrollTo(1,10000)\")\n",
    "time.sleep(2)\n",
    "\n",
    "html = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos todos los datos de jugadoes por todas las temporadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    url = player_stats_url.format(year)\n",
    "\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(1,10000)\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    with open(\"player/{}.html\".format(year), \"w+\", encoding='utf-8') as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1. Analizando las estadísticas con beautifulsoup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido que al traer todas las filas de todos los jugadores, me mostrará cabeceras intermedias entre registros, para este caso eliminaremos aquellas cabeceras, para tener netamente registros de jugadores, y eso lo hacemos en el siguiente fraagmento:\n",
    "``` python\n",
    "list_theads = soup.find_all('tr', class_ = \"thead\")\n",
    "for thead in list_theads:\n",
    "     thead.decompose()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PLAYER3](images/player_03.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in years: \n",
    "    with open(\"player/{}.html\".format(year), encoding='utf-8') as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    list_theads = soup.find_all('tr', class_ = \"thead\")\n",
    "    for thead in list_theads:\n",
    "        thead.decompose()\n",
    "    player_table = soup.find(id=\"per_game_stats\")\n",
    "    player = pd.read_html(str(player_table))[0]\n",
    "    player[\"year\"] = year\n",
    "    dfs.append(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.to_csv('players.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Descarga de datos del equipo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando predecimos quien ganará el MVP, queremos asegurarnos de insertar el registro de su equipo, para que el modelo de Aprendizaje automatico pueda ver ese registro, y usarlo como predictor. Scrapeamos los records del equipo por año, la posiciones de equipos por conferencia, el cuál corresponde a 2 tablas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TEAM1](images/team_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_standings.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    url = team_stats_url.format(year)\n",
    "    data = requests.get(url)\n",
    "    with open(\"team/{}.html\".format(year), \"w+\", encoding='utf-8') as f:\n",
    "        f.write(data.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tablas que queremos traer se cargan automáticamente, se necesitaría de javascript para poder cargar el resto del contenido mediante scroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TEAM2](images/team_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Analizando los datos del equipo con beautifulsoup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminaremos los titulos de las divisiones de conferencias, para solo tener registros acoplados a las conferencias `este y oeste`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in years:\n",
    "    with open(\"team/{}.html\".format(year), encoding='utf-8') as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    list_theads = soup.find_all('tr', class_ = 'thead')\n",
    "    for thead in list_theads:\n",
    "        thead.decompose()\n",
    "    team_table_E = soup.find(id=\"divs_standings_E\")\n",
    "    team_table_W = soup.find(id=\"divs_standings_W\")\n",
    "\n",
    "    team_E = pd.read_html(str(team_table_E))[0]\n",
    "    team_E[\"year\"] = year\n",
    "    team_E[\"team\"] = team_E['Eastern Conference']\n",
    "    del team_E['Eastern Conference']\n",
    "    \n",
    "    team_W = pd.read_html(str(team_table_W))[0]\n",
    "    team_W[\"year\"] = year\n",
    "    team_W[\"team\"] = team_W['Western Conference']\n",
    "    del team_W['Western Conference']\n",
    "\n",
    "    dfs.extend([team_E, team_W])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1. Combinando estadísticas de equipo con pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.concat(dfs)\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.to_csv('teams.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('basepyr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6054b2b7fc7533d51f31a0fc0655a38fed28e89654f7bac18c38f9dd03a83a8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
